# ROCm Strix Docker - Complete Reference

Minimal Docker base image for AMD Strix Halo (RDNA 3.5 / gfx1151) with ROCm PyTorch.

## Problem Solved

Standard containers fail on Strix Halo because:
1. Missing gfx1151 support in stable ROCm
2. Ubuntu Rolling ships Python 3.13 (PyTorch doesn't support it)
3. Debian pip silently falls back to CPU wheels

Solution: Ubuntu Rolling (driver compatibility) + UV (Python 3.12 isolation) + ROCm preview wheels.

## Version Clarification

- **PyTorch/ROCm Package**: 7.11.0rc1 (latest TheRock-based preview)
- **HIP Runtime**: 7.2.x (lower-level driver interface, shown in `torch.version.hip`)
- **torch.__version__**: 2.9.1+rocm7.11.0rc1

These are DIFFERENT metrics. 7.11 is the actual ROCm stack version.

## Required Environment Variables

MUST be numeric GIDs, NOT group names:
```
VIDEO_GID=44      # From: getent group video | cut -d: -f3
RENDER_GID=991    # From: getent group render | cut -d: -f3
```

String group names (video, render) DO NOT WORK in Docker Compose group_add.

## Files

### Dockerfile
```dockerfile
FROM ubuntu:rolling

ENV DEBIAN_FRONTEND=noninteractive
ENV UV_CACHE_DIR=/root/.cache/uv
ENV VIRTUAL_ENV=/app/.venv
ENV PATH="$VIRTUAL_ENV/bin:$PATH"
ENV HSA_OVERRIDE_GFX_VERSION=11.5.1

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip \
    libgl1 libglib2.0-0 libgomp1 \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

WORKDIR /app

RUN uv venv .venv --python 3.12 && \
    uv pip install --pre \
    torch torchvision torchaudio \
    --index-url https://rocm.prereleases.amd.com/whl/gfx1151/

COPY entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

ENTRYPOINT ["/entrypoint.sh"]
CMD ["python", "-c", "import time; print('ROCm ready'); time.sleep(86400)"]
```

### docker-compose.yml
```yaml
services:
  rocm-strix:
    build: .
    image: rocm-strix:latest
    container_name: rocm-strix
    privileged: true
    restart: unless-stopped
    devices:
      - "/dev/kfd:/dev/kfd"
      - "/dev/dri:/dev/dri"
    group_add:
      - "${VIDEO_GID}"
      - "${RENDER_GID}"
    volumes:
      - ./workspace:/workspace
    environment:
      - HSA_OVERRIDE_GFX_VERSION=11.5.1
      - HIP_VISIBLE_DEVICES=0
    ipc: host
    security_opt:
      - seccomp:unconfined
```

### entrypoint.sh
```bash
#!/bin/bash
set -e

echo "=== ROCm Strix Container ==="

if [ -z "$HSA_OVERRIDE_GFX_VERSION" ]; then
    export HSA_OVERRIDE_GFX_VERSION=11.5.1
fi

echo "[INFO] Checking GPU..."
python3 -c "
import torch
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')
    print(f'ROCm: {torch.version.hip}')
else:
    print('ERROR: GPU not detected')
    exit(1)
"

echo "[INFO] GPU check passed. Container ready."
exec "$@"
```

### .env
```
VIDEO_GID=44
RENDER_GID=991
```

## Build & Run

```bash
# 1. Get your GIDs
getent group video | cut -d: -f3
getent group render | cut -d: -f3

# 2. Fill .env with numeric values (NOT "video" or "render")

# 3. Build and start
docker compose up -d --build

# 4. Verify GPU detection
docker logs rocm-strix
docker exec rocm-strix python -c "import torch; print(torch.cuda.get_device_name(0))"
```

## Test Output (Working)

```
=== ROCm Strix Container ===
[INFO] Checking GPU...
GPU: Radeon 8060S Graphics
VRAM: 109.5 GB
ROCm: 7.2.53150-7b886380f9
[INFO] GPU check passed. Container ready.
```

## Key Technical Details

- **Index URL**: https://rocm.prereleases.amd.com/whl/gfx1151/ (required for gfx1151)
- **HSA_OVERRIDE_GFX_VERSION**: Must be 11.5.1 for Strix Halo
- **group_add**: Requires numeric GIDs, string names fail silently
- **devices**: /dev/kfd and /dev/dri required for GPU access
- **privileged**: Required for proper GPU permissions

## Verification Commands

```bash
# Inside container
python -c "import torch; print(torch.__version__)"  # 2.9.1+rocm7.11.0rc1
python -c "import torch; print(torch.version.hip)"  # 7.2.x (HIP runtime)
python -c "import torch; print(torch.cuda.is_available())"  # True
```
