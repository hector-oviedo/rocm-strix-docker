services:
  ollama:
    build: .
    image: ollama-strix:latest
    container_name: ollama-strix
    privileged: true
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ${OLLAMA_MODELS_DIR}:/ollama-models
    environment:
      - OLLAMA_MODEL=${OLLAMA_MODEL:-gpt-oss:20b}
      - OLLAMA_MODELS=/ollama-models
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_CONTEXT_LENGTH=${OLLAMA_CONTEXT_LENGTH:-8192}
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_KV_CACHE_TYPE=q8_0
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-5m}
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_MAX_LOADED_MODELS=1
      - HSA_OVERRIDE_GFX_VERSION=11.5.1
      - HIP_VISIBLE_DEVICES=0
      - AMD_SERIALIZE_KERNEL=1
    ipc: host
